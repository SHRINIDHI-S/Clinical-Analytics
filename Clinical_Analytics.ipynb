{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Building an Level Large Language Model (LLM) for Clinical Analytics\n",
        "\n",
        "## üìå Introduction\n",
        "In the medical field, **clinical text analytics** plays a crucial role in **automating documentation, summarizing patient reports, and assisting in medical decision-making**. Traditional models struggle with domain-specific terminology, but **Large Language Models (LLMs)** can help **generate, summarize, and analyze clinical text efficiently**.\n",
        "\n",
        "In this project, we will **build an LLM from scratch** and fine-tune it on **medical datasets** for real-world clinical applications.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Project Goal\n",
        "We aim to develop an **LLM trained on medical text** to:\n",
        "- ‚úÖ **Summarize clinical reports** for quick insights.  \n",
        "- ‚úÖ **Generate accurate medical documentation**.  \n",
        "- ‚úÖ **Answer medical questions** based on clinical text.  \n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Approach: How We'll Build It\n",
        "We will break the process into **key stages**:\n",
        "\n",
        "### 1Ô∏è‚É£ Data Acquisition\n",
        "- Use publicly available **medical text datasets** (e.g., **PubMed, MIMIC-III, MedQA**).\n",
        "- Preprocess text to remove noise, special characters, and ensure consistency.\n",
        "\n",
        "### 2Ô∏è‚É£ Tokenization & Preprocessing\n",
        "- Convert text into smaller subword units (**Byte-Pair Encoding (BPE)**).\n",
        "- Prepare data for **efficient training**.\n",
        "\n",
        "### 3Ô∏è‚É£ Model Architecture\n",
        "- Use a **Transformer-based model** similar to **GPT-2**.\n",
        "- Fine-tune a **pre-trained LLM** (e.g., **GPT-2, T5, LLaMA**) for **medical text generation**.\n",
        "\n",
        "### 4Ô∏è‚É£ Training the Model\n",
        "- Train the model using **clinical text**.\n",
        "- Use **mini-batch optimization, Cross-Entropy Loss, and Adam optimizer**.\n",
        "\n",
        "### 5Ô∏è‚É£ Model Evaluation\n",
        "- Assess performance using:\n",
        "  - **Perplexity (PPL)** ‚Üí Measures fluency.\n",
        "  - **BLEU Score** ‚Üí Measures text similarity with real clinical reports.\n",
        "\n",
        "### 6Ô∏è‚É£ Deploying & Testing\n",
        "- Generate **medical text** from input prompts.\n",
        "- Deploy the model as an **API for real-world usage**.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Expected Outcomes\n",
        "- ‚úÖ **A fine-tuned LLM that understands clinical text**.  \n",
        "- ‚úÖ **Can generate, summarize, and analyze patient reports**.  \n",
        "- ‚úÖ **Ready for real-world applications in clinical documentation & analytics**.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lZDA5tmii-NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 1: Data Acquisition  \n",
        "\n",
        "## üìå Data Selection  \n",
        "To build a **medical text-focused LLM**, we need a **high-quality dataset** that contains **real-world clinical notes, medical research abstracts, or question-answer pairs**. Some publicly available options include:\n",
        "\n",
        "1. **PubMedQA** üè• ‚Äì A dataset with **medical question-answer pairs** derived from PubMed abstracts.  \n",
        "2. **MIMIC-III / MIMIC-IV** üìë ‚Äì Contains **de-identified ICU clinical notes** (requires access approval).  \n",
        "3. **MedQA (USMLE Questions)** ü©∫ ‚Äì A dataset with **clinical exam questions and explanations**.  \n",
        "\n",
        "For this project, we will use **PubMedQA**, which is openly available and contains **high-quality medical text**.\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Steps\n",
        "1. **Download the PubMedQA dataset** from Hugging Face.  \n",
        "2. **Convert it into a structured Pandas DataFrame** for easy processing.  \n",
        "3. **Explore the dataset** to understand its contents.  \n"
      ],
      "metadata": {
        "id": "ZPvyas0ujM4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets\n",
        "\n",
        "# Install necessary libraries\n",
        "# !pip install datasets transformers torch rouge_score nltk"
      ],
      "metadata": {
        "id": "14bPveTnji3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ulOXgLbTiTGe",
        "outputId": "58329e92-59a5-4365-cc6c-b150b8d84d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pubid                                           question  \\\n",
              "0  21645374  Do mitochondria play a role in remodelling lac...   \n",
              "1  16418930  Landolt C and snellen e acuity: differences in...   \n",
              "2   9488747  Syncope during bathing in infants, a pediatric...   \n",
              "3  17208539  Are the long-term results of the transanal pul...   \n",
              "4  10808977  Can tailored interventions increase mammograph...   \n",
              "\n",
              "                                             context  \\\n",
              "0  {'contexts': ['Programmed cell death (PCD) is ...   \n",
              "1  {'contexts': ['Assessment of visual acuity dep...   \n",
              "2  {'contexts': ['Apparent life-threatening event...   \n",
              "3  {'contexts': ['The transanal endorectal pull-t...   \n",
              "4  {'contexts': ['Telephone counseling and tailor...   \n",
              "\n",
              "                                         long_answer final_decision  \n",
              "0  Results depicted mitochondrial dynamics in viv...            yes  \n",
              "1  Using the charts described, there was only a s...             no  \n",
              "2  \"Aquagenic maladies\" could be a pediatric form...            yes  \n",
              "3  Our long-term study showed significantly bette...             no  \n",
              "4  The effects of the intervention were most pron...            yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c71be763-0c18-4188-ab4e-859fa220b699\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pubid</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>long_answer</th>\n",
              "      <th>final_decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21645374</td>\n",
              "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
              "      <td>{'contexts': ['Programmed cell death (PCD) is ...</td>\n",
              "      <td>Results depicted mitochondrial dynamics in viv...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16418930</td>\n",
              "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
              "      <td>{'contexts': ['Assessment of visual acuity dep...</td>\n",
              "      <td>Using the charts described, there was only a s...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9488747</td>\n",
              "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
              "      <td>{'contexts': ['Apparent life-threatening event...</td>\n",
              "      <td>\"Aquagenic maladies\" could be a pediatric form...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17208539</td>\n",
              "      <td>Are the long-term results of the transanal pul...</td>\n",
              "      <td>{'contexts': ['The transanal endorectal pull-t...</td>\n",
              "      <td>Our long-term study showed significantly bette...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10808977</td>\n",
              "      <td>Can tailored interventions increase mammograph...</td>\n",
              "      <td>{'contexts': ['Telephone counseling and tailor...</td>\n",
              "      <td>The effects of the intervention were most pron...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c71be763-0c18-4188-ab4e-859fa220b699')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c71be763-0c18-4188-ab4e-859fa220b699 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c71be763-0c18-4188-ab4e-859fa220b699');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f239ae6-2219-4486-b181-e22c623789cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f239ae6-2219-4486-b181-e22c623789cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f239ae6-2219-4486-b181-e22c623789cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"pubid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5471418,\n        \"min\": 1571683,\n        \"max\": 29112560,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          26348845,\n          10973547,\n          26163474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Pap smears with glandular cell abnormalities: Are they detected by rapid prescreening?\",\n          \"Are patients with Werlhof's disease at increased risk for bleeding complications when undergoing cardiac surgery?\",\n          \"Is there a connection between sublingual varices and hypertension?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Pap smears with glandular cell abnormalities are often flagged as abnormal by RPS, and this results in a sensitivity of 36.4% (at the AGC threshold). Most importantly, some cases of AGC are detected on Pap smears by RPS only, and this demonstrates that RPS is a valuable QA method.\",\n          \"Patients with WD may possibly undergo cardiac surgery without a markedly enhanced risk for bleeding complications despite a more than usual transfusion requirement and significantly lower platelet counts perioperatively.\",\n          \"An association was found between sublingual varices and hypertension. Examining the lateral borders of the tongue is easily done, causes no harm and could be a valuable method for the dental profession to take active part in preventive healthcare.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"yes\",\n          \"no\",\n          \"maybe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import torch\n",
        "import math\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from transformers import pipeline\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "# Load PubMedQA dataset from Hugging Face\n",
        "dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")\n",
        "\n",
        "# Convert dataset to Pandas DataFrame\n",
        "df = pd.DataFrame(dataset[\"train\"])\n",
        "\n",
        "# Display first few rows to explore structure\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display column names\n",
        "print(\"Dataset Columns:\", df.columns)\n",
        "\n",
        "# Print a sample of the dataset\n",
        "print(\"\\nSample Data:\\n\")\n",
        "print(df.sample(3))  # Show 3 random examples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-SpcBOoi54z",
        "outputId": "c4223cd6-d86f-4857-a727-a63cdcd23a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Columns: Index(['pubid', 'question', 'context', 'long_answer', 'final_decision'], dtype='object')\n",
            "\n",
            "Sample Data:\n",
            "\n",
            "        pubid                                           question  \\\n",
            "482  15477551  Chronic progressive cervical myelopathy with H...   \n",
            "46   19504993          It's Fournier's gangrene still dangerous?   \n",
            "255  24434052  Are we seeing the effects of public awareness ...   \n",
            "\n",
            "                                               context  \\\n",
            "482  {'contexts': ['To investigate the role of huma...   \n",
            "46   {'contexts': ['Fournier's gangrene is known to...   \n",
            "255  {'contexts': ['The last 20 years has seen a ma...   \n",
            "\n",
            "                                           long_answer final_decision  \n",
            "482  These four cases may belong to a variant form ...            yes  \n",
            "46   The interval from the onset of clinical sympto...            yes  \n",
            "255  The proportion of thin 0-1 mm melanomas presen...          maybe  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 2: Text Preprocessing & Tokenization  \n",
        "\n",
        "\n",
        "Before training, we need to:  \n",
        "‚úÖ **Clean the text** ‚Üí Remove unwanted characters, whitespace, and formatting issues.  \n",
        "‚úÖ **Tokenize the text** ‚Üí Convert raw text into smaller subword units using a **Byte-Pair Encoding (BPE) tokenizer**.  \n",
        "‚úÖ **Prepare data for efficient training** ‚Üí Ensure tokens are in the right\n"
      ],
      "metadata": {
        "id": "bZWEm9btj3iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clean the Clinical Text\n",
        "\n",
        "\n",
        "- Converts text to lowercase.\n",
        "- Removes special characters except for medical-relevant ones.\n",
        "- Strips unnecessary spaces."
      ],
      "metadata": {
        "id": "xDZ4pPlLkln3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Function to clean clinical text by removing unnecessary characters.\n",
        "    \"\"\"\n",
        "    if isinstance(text, dict):  # Extract text if it's stored in a dictionary\n",
        "        text = text.get(\"text\", \"\")\n",
        "\n",
        "    if not isinstance(text, str):  # Ensure text is a string\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower().strip()  # Convert to lowercase and strip whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'[^\\w\\s.,-]', '', text)  # Remove special characters except punctuation\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to dataset\n",
        "df[\"context\"] = df[\"context\"].apply(clean_text)\n",
        "df[\"long_answer\"] = df[\"long_answer\"].apply(clean_text)\n",
        "\n",
        "print(\"‚úÖ Clinical text cleaned!\")\n",
        "\n",
        "# Display cleaned text\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "mLzNDQ9ijsTT",
        "outputId": "5440cb78-0122-4fb4-b6ad-f3ebc2c9a44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Clinical text cleaned!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      pubid                                           question context  \\\n",
              "0  21645374  Do mitochondria play a role in remodelling lac...           \n",
              "1  16418930  Landolt C and snellen e acuity: differences in...           \n",
              "2   9488747  Syncope during bathing in infants, a pediatric...           \n",
              "3  17208539  Are the long-term results of the transanal pul...           \n",
              "4  10808977  Can tailored interventions increase mammograph...           \n",
              "\n",
              "                                         long_answer final_decision  \n",
              "0  results depicted mitochondrial dynamics in viv...            yes  \n",
              "1  using the charts described, there was only a s...             no  \n",
              "2  aquagenic maladies could be a pediatric form o...            yes  \n",
              "3  our long-term study showed significantly bette...             no  \n",
              "4  the effects of the intervention were most pron...            yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6749d383-b627-4084-b0f9-6d60560213fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pubid</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>long_answer</th>\n",
              "      <th>final_decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21645374</td>\n",
              "      <td>Do mitochondria play a role in remodelling lac...</td>\n",
              "      <td></td>\n",
              "      <td>results depicted mitochondrial dynamics in viv...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16418930</td>\n",
              "      <td>Landolt C and snellen e acuity: differences in...</td>\n",
              "      <td></td>\n",
              "      <td>using the charts described, there was only a s...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9488747</td>\n",
              "      <td>Syncope during bathing in infants, a pediatric...</td>\n",
              "      <td></td>\n",
              "      <td>aquagenic maladies could be a pediatric form o...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17208539</td>\n",
              "      <td>Are the long-term results of the transanal pul...</td>\n",
              "      <td></td>\n",
              "      <td>our long-term study showed significantly bette...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10808977</td>\n",
              "      <td>Can tailored interventions increase mammograph...</td>\n",
              "      <td></td>\n",
              "      <td>the effects of the intervention were most pron...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6749d383-b627-4084-b0f9-6d60560213fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6749d383-b627-4084-b0f9-6d60560213fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6749d383-b627-4084-b0f9-6d60560213fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3976e426-0d40-4277-a928-b8d93c31b8ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3976e426-0d40-4277-a928-b8d93c31b8ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3976e426-0d40-4277-a928-b8d93c31b8ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"pubid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5471418,\n        \"min\": 1571683,\n        \"max\": 29112560,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          26348845,\n          10973547,\n          26163474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Pap smears with glandular cell abnormalities: Are they detected by rapid prescreening?\",\n          \"Are patients with Werlhof's disease at increased risk for bleeding complications when undergoing cardiac surgery?\",\n          \"Is there a connection between sublingual varices and hypertension?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"pap smears with glandular cell abnormalities are often flagged as abnormal by rps, and this results in a sensitivity of 36.4 at the agc threshold. most importantly, some cases of agc are detected on pap smears by rps only, and this demonstrates that rps is a valuable qa method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing Medical Text\n",
        "\n",
        "- Uses T5 tokenizer (since we may fine-tune T5 or GPT-2).\n",
        "- Converts text into token IDs.\n",
        "- Adds padding & truncation for uniform sequence length."
      ],
      "metadata": {
        "id": "O8oqHKyNkaVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Ensure GPT-2 has a padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as padding\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    \"\"\"\n",
        "    Tokenize context and long_answer while ensuring padding consistency.\n",
        "    \"\"\"\n",
        "    input_encoding = tokenizer(\n",
        "        example[\"context\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,  # Ensure consistent input length\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    label_encoding = tokenizer(\n",
        "        example[\"long_answer\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,  # Match input length\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    labels = label_encoding[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100  # Ignore padding tokens for loss computation\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_encoding[\"input_ids\"].squeeze(0),\n",
        "        \"labels\": labels.squeeze(0),\n",
        "    }\n",
        "\n",
        "# Apply tokenization and correctly store it in a new DataFrame\n",
        "tokenized_data = df.apply(tokenize_function, axis=1, result_type=\"expand\")\n",
        "\n",
        "# Merge tokenized data back into the original DataFrame\n",
        "df = pd.concat([df, tokenized_data], axis=1)\n",
        "\n",
        "print(\"‚úÖ Tokenization completed successfully!\")\n",
        "print(df.head())  # Check if input_ids column is present\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BprG6vGCvsio",
        "outputId": "aa12f8f4-74d8-4dff-8dca-40641ba6637c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tokenization completed successfully!\n",
            "      pubid                                           question context  \\\n",
            "0  21645374  Do mitochondria play a role in remodelling lac...           \n",
            "1  16418930  Landolt C and snellen e acuity: differences in...           \n",
            "2   9488747  Syncope during bathing in infants, a pediatric...           \n",
            "3  17208539  Are the long-term results of the transanal pul...           \n",
            "4  10808977  Can tailored interventions increase mammograph...           \n",
            "\n",
            "                                         long_answer final_decision  \\\n",
            "0  results depicted mitochondrial dynamics in viv...            yes   \n",
            "1  using the charts described, there was only a s...             no   \n",
            "2  aquagenic maladies could be a pediatric form o...            yes   \n",
            "3  our long-term study showed significantly bette...             no   \n",
            "4  the effects of the intervention were most pron...            yes   \n",
            "\n",
            "                                           input_ids  \\\n",
            "0  [tensor(50256), tensor(50256), tensor(50256), ...   \n",
            "1  [tensor(50256), tensor(50256), tensor(50256), ...   \n",
            "2  [tensor(50256), tensor(50256), tensor(50256), ...   \n",
            "3  [tensor(50256), tensor(50256), tensor(50256), ...   \n",
            "4  [tensor(50256), tensor(50256), tensor(50256), ...   \n",
            "\n",
            "                                              labels  \n",
            "0  [tensor(43420), tensor(18904), tensor(32873), ...  \n",
            "1  [tensor(3500), tensor(262), tensor(15907), ten...  \n",
            "2  [tensor(36129), tensor(11286), tensor(291), te...  \n",
            "3  [tensor(454), tensor(890), tensor(12), tensor(...  \n",
            "4  [tensor(1169), tensor(3048), tensor(286), tens...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 3: Defining the LLM Model Architecture\n",
        "\n",
        "## üìå Steps\n",
        "‚úÖ **Choose a Transformer-based model** (GPT-2 or T5) for medical text generation.  \n",
        "‚úÖ **Load a pre-trained model** to fine-tune on clinical datasets.  \n",
        "‚úÖ **Prepare the model for training** (moving it to GPU if available).  \n"
      ],
      "metadata": {
        "id": "pQu2RM2Qk8iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Pre-Trained GPT-2 Model\n",
        "\n",
        "\n",
        "- Loads GPT-2, a Transformer-based LLM.\n",
        "- Uses Hugging Face's AutoModelForCausalLM for text generation."
      ],
      "metadata": {
        "id": "2TLfaCRBlQ7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Choose a pre-trained model (GPT-2 for generative tasks)\n",
        "model_name = \"gpt2\"  # Can be replaced with \"t5-small\" or \"facebook/opt-1.3b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"‚úÖ Loaded {model_name} successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ouWMz6kUIz",
        "outputId": "197cd379-5cf0-484a-8886-144cd8494239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded gpt2 successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understanding the Model Architecture\n",
        "\n",
        "- Displays the GPT-2 model architecture.\n",
        "- Shows number of trainable parameters."
      ],
      "metadata": {
        "id": "jXk65_56lWzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "print(model)\n",
        "print(f\"\\nTotal Trainable Parameters: {sum(p.numel() for p in model.parameters())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj_61q3jlIsU",
        "outputId": "a4a9ef19-aff2-4e93-8754-aa03fefdd732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "Total Trainable Parameters: 124439808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 4: Fine-Tuning GPT-2 on Medical Text\n",
        "\n",
        "## üìå Steps\n",
        "‚úÖ **Convert tokenized text into a format suitable for training**.  \n",
        "‚úÖ **Ensure correct PyTorch tensor structure for `input_ids` and `labels`**.  \n",
        "‚úÖ **Fine-tune GPT-2 on medical text using PyTorch & Hugging Face's `Trainer`**.  \n"
      ],
      "metadata": {
        "id": "nynsjPmWlyV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ensure Correct Tensor Format\n",
        "- Ensures input_ids and labels are correctly formatted as PyTorch tensors.\n",
        "- Avoids unnecessary tensor conversion warnings using .clone().detach()."
      ],
      "metadata": {
        "id": "ZhnTipW8o6ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Ensure GPT-2 has a padding token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Set padding token ID\n",
        "\n",
        "print(f\"‚úÖ Padding token set to: {tokenizer.pad_token}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y2ngYCBnIlw",
        "outputId": "bf8e0a15-1940-4bd2-9526-223f74cfb1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Padding token set to: <|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert Data into PyTorch Dataset\n",
        "\n",
        "- Formats the dataset into a PyTorch Dataset class.\n",
        "- Uses pad_sequence() to ensure uniform tensor size for batch processing"
      ],
      "metadata": {
        "id": "TatefTNUpEra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalTextDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.input_ids = pad_sequence(\n",
        "            df[\"input_ids\"].tolist(),\n",
        "            batch_first=True,\n",
        "            padding_value=tokenizer.pad_token_id  # ‚úÖ Ensure padding value is properly set\n",
        "        )\n",
        "\n",
        "        self.labels = pad_sequence(\n",
        "            df[\"labels\"].tolist(),\n",
        "            batch_first=True,\n",
        "            padding_value=-100  # ‚úÖ Standard practice for ignoring padded tokens\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "tLhxjYhzpO8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Fix tokenization by converting lists of tensors into proper PyTorch tensors\n",
        "df[\"input_ids\"] = df[\"input_ids\"].apply(lambda x: x[0].clone().detach())  # Avoids unnecessary tensor creation\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda x: x[0].clone().detach())  # Ensures correct tensor format\n",
        "\n",
        "# Verify the new format\n",
        "print(df[\"input_ids\"].head())\n",
        "print(df[\"labels\"].head())\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ymXSGShE1d4B",
        "outputId": "e1e4a419-7b93-4a3c-ea50-cd69775558e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Fix tokenization by converting lists of tensors into proper PyTorch tensors\\ndf[\"input_ids\"] = df[\"input_ids\"].apply(lambda x: x[0].clone().detach())  # Avoids unnecessary tensor creation\\ndf[\"labels\"] = df[\"labels\"].apply(lambda x: x[0].clone().detach())  # Ensures correct tensor format\\n\\n# Verify the new format\\nprint(df[\"input_ids\"].head())\\nprint(df[\"labels\"].head())\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXK_Gu6836hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train and evaluation sets\n",
        "split_ratio = 0.1  # 90% training, 10% validation\n",
        "split_index = int(len(df) * (1 - split_ratio))\n",
        "\n",
        "train_df = df.iloc[:split_index]\n",
        "eval_df = df.iloc[split_index:]\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = MedicalTextDataset(train_df)\n",
        "eval_dataset = MedicalTextDataset(eval_df)\n",
        "\n",
        "print(\"‚úÖ Training and Evaluation datasets created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pQ9oRi01MQw",
        "outputId": "dd5771bd-fb35-4caf-8494-e8a4d1049e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training and Evaluation datasets created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MedicalTextDataset(train_df)\n",
        "eval_dataset = MedicalTextDataset(eval_df)\n",
        "\n",
        "print(\"‚úÖ Training and Evaluation datasets created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onejbQ-04FEz",
        "outputId": "3b3ba339-430b-4308-f977-94694a227b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training and Evaluation datasets created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Reload dataset with corrected format\n",
        "train_dataset = MedicalTextDataset(df)\n",
        "\n",
        "print(\"‚úÖ Dataset is ready for training!\")\n",
        "'''"
      ],
      "metadata": {
        "id": "cZBVfQlW1Ita"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Training Parameters\n",
        "\n",
        "- Defines the learning rate, batch size, and number of epochs.\n",
        "- Uses CrossEntropyLoss as the loss function.\n",
        "- Uses Adam optimizer for updating model weights."
      ],
      "metadata": {
        "id": "g4aqsE8UpSR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduce Batch Size & Enable Gradient Checkpointing\n",
        "üìå Modify TrainingArguments to lower memory usage"
      ],
      "metadata": {
        "id": "DXbVqlKMrof5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "model.config.use_cache = False\n",
        "print(\"‚úÖ `use_cache` disabled for gradient checkpointing!\")\n",
        "'''\n",
        "\n",
        "# Define improved training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2_medical_improved\",\n",
        "    per_device_train_batch_size=4,  # Lower batch size to prevent RAM crashes\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=2,  # More training epochs\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=3e-5,  # Reduced learning rate for better stability\n",
        "    lr_scheduler_type=\"cosine\",  # Use cosine learning rate scheduling\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "# Restart training\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vjQuuZCEpb0G",
        "outputId": "f59a5aec-ceb6-495c-8030-fe742dd7d133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [224/224 6:07:54, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.115085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=224, training_loss=7.0616030011858255, metrics={'train_runtime': 22177.4582, 'train_samples_per_second': 0.081, 'train_steps_per_second': 0.01, 'total_flos': 467190153216000.0, 'train_loss': 7.0616030011858255, 'epoch': 1.9866666666666668})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Save trained model before evaluation\n",
        "save_directory = \"./gpt2_medical_finetuned\"\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"‚úÖ Model and tokenizer saved to {save_directory}\")\n",
        "\n",
        "# Reload model for evaluation (optional, to ensure we're using the saved model)\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(save_directory)\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "print(\"‚úÖ Model reloaded for evaluation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNU1vV2TEiwU",
        "outputId": "cce15064-08b3-4365-c217-4e2808da0924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model and tokenizer saved to ./gpt2_medical_finetuned\n",
            "‚úÖ Model reloaded for evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensure Dataset is in PyTorch Format\n",
        "- Converting dataset into torch format prevents unnecessary conversions, saving RAM."
      ],
      "metadata": {
        "id": "xM1xzxnvr253"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 5: Generating and Evaluating Medical Text\n",
        "\n",
        "## üìå What We Will Do\n",
        "‚úÖ **Generate medical text using the trained model**.  \n",
        "‚úÖ **Evaluate performance using standard NLP metrics**.  \n",
        "\n",
        "## üìä Evaluation Metrics\n",
        "üîπ **Perplexity (PPL)** ‚Üí Measures fluency of generated text.  \n",
        "üîπ **BLEU Score** ‚Üí Measures similarity with real clinical reports.  \n",
        "üîπ **ROUGE Score** ‚Üí Measures how well the generated text summarizes information.  \n"
      ],
      "metadata": {
        "id": "qNiftAoitVbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Medical Text\n",
        "\n",
        "- Uses GPT-2 to generate clinical text from an input prompt.\n",
        "- Sets temperature (randomness) and top-k sampling (controls diversity)."
      ],
      "metadata": {
        "id": "TJfV_JNGtZ2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Proceed with Evaluation\n",
        "from transformers import pipeline\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "# Load text generation pipeline\n",
        "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Define a sample medical input prompt\n",
        "prompt = \"Patient diagnosed with Type 2 Diabetes, symptoms include\"\n",
        "\n",
        "# Generate text\n",
        "generated_text = text_generator(prompt, max_length=100, num_return_sequences=1, temperature=0.7, top_k=50)\n",
        "\n",
        "# Print generated medical text\n",
        "print(\"Generated Clinical Text:\\n\", generated_text[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkcze6los8Bz",
        "outputId": "dfdcc980-8dd4-4d82-c3a0-cbde3771b02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Clinical Text:\n",
            " Patient diagnosed with Type 2 Diabetes, symptoms include a normalization of the insulin-dependent glucose-induced insulin resistance and, in a minority, a high-grade insulin-dependent glucose-induced glucose-induced diabetes, or hypertension.\n",
            "\n",
            "hoc.c. of the study, in patients with the same-type diabetes, significant patients with this disease had significantly higher levels of gastric or systemic insulin-dependent glucose. In patients with a low-grade or a low-grade diabetes,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Generate Medical Text for Custom Input\n",
        "user_prompt = input(\"Enter a medical prompt: \")\n",
        "\n",
        "# Generate text based on the user input\n",
        "generated_response = text_generator(user_prompt, max_length=100, num_return_sequences=1, temperature=0.7, top_k=50)\n",
        "\n",
        "# Print the generated text\n",
        "print(\"\\nü©∫ Generated Clinical Text:\\n\", generated_response[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNmx7XPTviK",
        "outputId": "71a1d1c1-e815-47f1-99c6-3ed4d6275e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a medical prompt: Symptoms of Fever includes,\n",
            "\n",
            "ü©∫ Generated Clinical Text:\n",
            " Symptoms of Fever includes, in many cases, a lack of air-ventricular tachycardia. however, other risk factors may be associated with this. and the incidence may be increased with a higher degree of severity. patients with a low fever and, thus, are more likely to be hospitalized. to determine the association of the low-grade and- to the high-grade patients of the two cases. patients with a high fever and a high-grade with a low-grade.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model Using Perplexity (PPL)\n",
        "\n",
        "- Uses the Cross-Entropy loss to compute Perplexity (PPL).\n",
        "- Lower PPL means better fluency."
      ],
      "metadata": {
        "id": "eNCs4Y4hthte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    loss = outputs.loss.item()\n",
        "    perplexity = math.exp(loss)\n",
        "    return perplexity\n",
        "\n",
        "# Sample medical sentence\n",
        "sample_text = \"Patient was admitted with severe chest pain and diagnosed with myocardial infarction.\"\n",
        "\n",
        "# Compute Perplexity\n",
        "ppl_score = calculate_perplexity(model, tokenizer, sample_text)\n",
        "print(f\"‚úÖ Perplexity Score: {ppl_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-ggXLolteBB",
        "outputId": "e6f288ee-8b69-4733-97aa-4a691c772d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Perplexity Score: 16.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model Using BLEU Score\n",
        "\n",
        "- Compares generated text vs. real clinical reports using BLEU Score.\n",
        "- Higher BLEU means better text similarity."
      ],
      "metadata": {
        "id": "iYWuY38gtxfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Reference real medical text\n",
        "reference_text = [\"Patient was diagnosed with severe chest pain and found to have a heart attack.\"]\n",
        "\n",
        "# Generate a prediction using the model\n",
        "generated_text = text_generator(\"Patient was diagnosed with severe chest pain\", max_length=30)[0][\"generated_text\"]\n",
        "\n",
        "# Tokenize both texts\n",
        "reference_tokens = [reference_text[0].split()]\n",
        "generated_tokens = generated_text.split()\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_score = sentence_bleu(reference_tokens, generated_tokens)\n",
        "\n",
        "print(f\"‚úÖ BLEU Score: {bleu_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8efFTR2trlx",
        "outputId": "3b1d892b-3a6b-46c9-8d60-9efd1a7f8c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BLEU Score: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model Using ROUGE Score\n",
        "\n",
        "- Measures how well the generated text summarizes medical information.\n",
        "- Higher ROUGE scores mean better summarization."
      ],
      "metadata": {
        "id": "InFdDufMt6Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rouge_score"
      ],
      "metadata": {
        "id": "5jIVDbrDuBsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Define a reference summary and model-generated summary\n",
        "reference_summary = \"Patient admitted with chest pain, diagnosed with myocardial infarction.\"\n",
        "generated_summary = generated_text\n",
        "\n",
        "# Compute ROUGE score\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "scores = scorer.score(reference_summary, generated_summary)\n",
        "\n",
        "print(f\"‚úÖ ROUGE Scores: {scores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BvvCtYjt2e3",
        "outputId": "f110bd49-521d-4d4b-ae6c-2331b16efd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ROUGE Scores: {'rouge1': Score(precision=0.19230769230769232, recall=0.5555555555555556, fmeasure=0.28571428571428575), 'rouge2': Score(precision=0.08, recall=0.25, fmeasure=0.12121212121212122), 'rougeL': Score(precision=0.15384615384615385, recall=0.4444444444444444, fmeasure=0.2285714285714286)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Step 6: Fine-Tuning Improvements & Deployment\n",
        "\n",
        "## üìå What We Will Do\n",
        "‚úÖ **Further improve the fine-tuned model**.  \n",
        "‚úÖ **Deploy the model as an API for real-world usage**.  \n",
        "\n",
        "## üîÑ Fine-Tuning Improvements\n",
        "- Increase training epochs for better performance.\n",
        "- Use a **larger dataset** or more diverse examples.\n",
        "- Apply **data augmentation techniques**.\n",
        "- Implement **hyperparameter tuning**.\n",
        "\n",
        "## üåç Deploying the Model\n",
        "- Convert model to a deployable format (ONNX, TorchScript, or HF API).\n",
        "- Build an API using FastAPI.\n",
        "- Deploy it on cloud platforms like AWS, Hugging Face Spaces, or Google Cloud.\n"
      ],
      "metadata": {
        "id": "yYEbiiONuU2N"
      }
    }
  ]
}